\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}
\usepackage{balance}
\usepackage{indentfirst}
\usepackage{cite}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\setlength{\parindent}{1em}
% \cvprfinalcopy % *** Uncomment this line for the final submission
\cvprfinalcopy
\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\ifcvprfinal\pagestyle{empty}\fi
% Pages are numbered in submission mode, and unnumbered in camera-ready
\begin{document}
\title{Latent Task Adaptation with Large-scale Hierarchies}
\author{Yufeng Jiang}
\date{\today}
\maketitle
\begin{abstract}
Recent years have witnessed the success of large-scale image classification systems that are able to identify objects among thousands of possible labels. However, it is yet unclear how general classifiers such as ones trained on ImageNet can be optimally adapted to specific tasks, each of which only covers a semantically related subset of all the objects in the world. In this paper authors propose a novel probabilistic model that jointly identifies the underlying task and performs prediction with a linear-time probabilistic inference algorithm, given a set of query images from a latent task. Empirical results based on the ImageNet data showed significant performance increase over several baseline algorithms.
\end{abstract}
\section{Introduction}
Recent years have witnessed a growing interest in object classification tasks involving specific sets of object categories, such as fine-grained object classification~\cite{Birdlets,Novel} and home object recognition in visual robotics. Existing methods in the literature generally describe algorithms that are trained and tested on exactly the same task. A dog breed classifier is trained and tested on dogs and a cat breed classifier done on cats, without the use of out-of-task images.\\
\indent However, two observations may render this ``one classifier per task'' approach suboptimal. First, itâ€™s known that using images of related tasks is often beneficial to build a better model for the general visual world~\cite{transfer}, which serves as a better regularization for the specific task as well. Second, object categories in the real world are often organized in, or at least well modeled by, a nested taxonomical hierarchy ({\emph e.g.} Figure \ref{fig}), with classification tasks corresponding to intermediate subtrees in this hierarchy, and recent efforts on the ImageNet challenge \cite{image,Imagenet} have leveraged the use of large-scale data to learn such information. While it is reasonable to train separate classifiers for specific tasks.
\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{2.png}
\end{center}
\caption{Top: Visualization of specific object classification tasks of interest in daily life, which are often subtrees in a large scale object taxonomy, {\emph e.g.} the ImageNet hierarchy. Bottom: Adapting the ImageNet classifier allows us to perform accurate prediction (bold), while the original classifier prediction (in parentheses) suffers from a higher confusion.}
\label{fig}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{3.png}
\end{center}
\caption{Left: the generative model for the latent task and corresponding query images. Right: the prior probabilities of the latent tasks from psychological study, along the path leading to the synsets oriental poppy and can opener respectively, with darker color indicating higher probability.}
\label{fig2}
\end{figure}
\section{A Generative Model for Task Adaptation}
Formally, authors define a classification task to be a subset of all the possible object labels that are semantically related. During testing time, a number of query images are randomly sampled from the labels belonging to a task, and the learning algorithm needs to give predictions on these images. In this section they propose a probabilistic framework that models the generation of latent tasks and the test time query images.\\
\indent As stated in the previous section, they are interested in the scenario when the task is latent, {\emph i.e.} only implicitly specified by the query images. We introduce two key components for modeling the generative process of query images: a latent task space that defines possible tasks and their probability, and a procedure to sample query images given a specific latent task. Specifically, we propose the graphical model in Figure \ref{fig2} which generates a set of $N$ query images when given $T$ possible tasks and $K$ object categories. 
\subsection{Latent Task Space}
\balance
In this paper authors are mainly interested in modeling the frequency of various tasks in a general and large-scale setting1. Prior research on psychology and Bayesian generalization~\cite{bayesian,Generalization} have shown that people favor basic-level concepts, which could be well modeled by a Erlang prior with respect to the size $|h|$ of each latent task, defined as the number of leaf nodes in the subtree rooted at the task:
\begin{gather}
P(h) = \alpha \varpropto (|h|/\sigma^2)exp(-|h|/\sigma)
\end{gather}
which favors medium-sized tasks corresponding to basic level concepts.
{\small
\bibliographystyle{ieee}
\bibliography{latent}
}
\end{document}